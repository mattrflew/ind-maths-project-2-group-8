{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Parameter Search,  put it between Parameters Part and Obstacle Functions\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define a function to evaluate the model with given parameters\n",
    "def evaluate_model(params):\n",
    "    # Update the parameters\n",
    "    global lam_c, lam_a, lam_m, lam_g, R_bird, R_min, bird_speed_max\n",
    "    \n",
    "    lam_c = params['lam_c']\n",
    "    lam_a = params['lam_a']\n",
    "    lam_m = params['lam_m']\n",
    "    lam_g = params['lam_g']\n",
    "    R_bird = params['R_bird']\n",
    "    R_min = params['R_min']\n",
    "    bird_speed_max = params['bird_speed_max']\n",
    "    \n",
    "    # Reset bird positions\n",
    "    x, y, vx, vy = flock_uniform(N, L, bird_speed)\n",
    "    \n",
    "    # Run the simulation for a few steps and calculate some performance metric\n",
    "    for _ in range(10):  # You can use a larger number of steps for more accuracy\n",
    "        x, y, vx, vy = step(x, y, vx, vy, L, R_bird, R_min, N, dt, bird_speed_max, lam_a, lam_c, lam_m, lam_g, goal_x, goal_y, x_obstacle_list, y_obstacle_list)\n",
    "\n",
    "    # Define an evaluation metric, e.g., how compact the flock stays\n",
    "    average_distance_to_goal = np.mean([distance(np.array([goal_x, goal_y]), np.array([x[i][0], y[i][0]])) for i in range(N)])\n",
    "    \n",
    "    # A smaller average distance to the goal means better performance\n",
    "    return average_distance_to_goal\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'lam_c': [0.1, 0.3, 0.5],\n",
    "    'lam_a': [0.3, 0.5, 0.7],\n",
    "    'lam_m': [0.2, 0.4, 0.6],\n",
    "    'lam_g': [0.1, 0.2, 0.3],\n",
    "    'R_bird': [0.5, 0.8, 1.0],\n",
    "    'R_min': [0.2, 0.3, 0.4],\n",
    "    'bird_speed_max': [0.8, 1.0, 1.2]\n",
    "}\n",
    "\n",
    "# Iterate through the grid\n",
    "param_combinations = ParameterGrid(param_grid)\n",
    "best_params = None\n",
    "best_score = float('inf')\n",
    "\n",
    "for params in param_combinations:\n",
    "    score = evaluate_model(params)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best parameters found:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "# Update the parameters with the best found values\n",
    "lam_c = best_params['lam_c']\n",
    "lam_a = best_params['lam_a']\n",
    "lam_m = best_params['lam_m']\n",
    "lam_g = best_params['lam_g']\n",
    "R_bird = best_params['R_bird']\n",
    "R_min = best_params['R_min']\n",
    "bird_speed_max = best_params['bird_speed_max']\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
